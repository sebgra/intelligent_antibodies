{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = \"torch\"\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from modules.dataset import DatasetFactory\n",
    "from modules.encoding import NLFEncoder\n",
    "\n",
    "from modules.data.loader import SequenceEncodingDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../data/SAbDab\"\n",
    "\n",
    "df_match = pd.read_csv(os.path.join(dataset_dir, \"data.csv\"), sep=\";\")\n",
    "df_seq = pd.read_csv(os.path.join(dataset_dir, \"sequences.csv\"), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter \n",
    "\n",
    "Remove keys which does not have both an antigen and an anticorps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_match[df_match[\"ab\"].isin(df_seq[\"seq_id\"]) & df_match[\"ag\"].isin(df_seq[\"seq_id\"])]\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "### NLF\n",
    "\n",
    "We want to encode the sequence first, and retrieve the encoded for each sequence in the join later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = NLFEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = df_seq[\"sequence\"].values\n",
    "encoded_seq = encoder.encode(seq, vector_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_id_to_nlf = {seq_id: nlf for seq_id, nlf in zip(df_seq[\"seq_id\"], encoded_seq)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_filtered[[\"ab\", \"ag\"]] \n",
    "y = df_filtered[[\"interaction\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_loader = SequenceEncodingDataGenerator(x_train, y_train, seq_id_to_nlf, batch_size=32)\n",
    "test_ds_loader = SequenceEncodingDataGenerator(x_test, y_test, seq_id_to_nlf, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = train_ds_loader[0]\n",
    "input_dimensions = example_batch[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_input1 = layers.Input(shape=input_dimensions, name='seq_ag')\n",
    "seq_input2 = layers.Input(shape=input_dimensions, name='seq_ab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional modules\n",
    "filters = 16\n",
    "\n",
    "\n",
    "conv01 = layers.Conv1D(filters, 11, padding='same', activation=\"relu\")\n",
    "mp1 = layers.MaxPooling1D(3)\n",
    "conv02 = layers.Conv1D(filters*2, 7, padding='same', activation=\"relu\")\n",
    "mp2 = layers.MaxPooling1D(3)\n",
    "conv03 = layers.Conv1D(filters*4, 3, padding='same', activation=\"relu\")\n",
    "mp3 = layers.MaxPooling1D(3)\n",
    "conv04 = layers.Conv1D(filters*2, 3, padding='same', activation=\"relu\")\n",
    "mp4 = layers.MaxPooling1D(3)\n",
    "\n",
    "gru = layers.Bidirectional(layers.GRU(filters, return_sequences=False))\n",
    "\n",
    "def siamese_propagation(x):\n",
    "    x = conv01(x)\n",
    "    x = mp1(x)\n",
    "\n",
    "    x = conv02(x)\n",
    "    x = mp2(x)\n",
    "\n",
    "    # x = conv03(x)\n",
    "    # x = mp3(x)\n",
    "\n",
    "    # x = conv04(x)\n",
    "    # x = mp4(x)\n",
    "\n",
    "    x_gru = gru(x)\n",
    "    return x_gru\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(left, right):\n",
    "    left = siamese_propagation(left)\n",
    "    right = siamese_propagation(right)\n",
    "\n",
    "    merge = layers.multiply([left, right])\n",
    "\n",
    "    # merge = layers.Dense(filters*2, activation='relu')(merge)\n",
    "    merge = layers.Dropout(0.2)(merge)\n",
    "    return layers.Dense(1, activation='sigmoid')(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    pred_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = tp / (pred_pos + K.epsilon())\n",
    "    recall = tp / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def mcc(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "    return (tp + tn) / (tp + tn + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_true, y_pred):\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    loss = - K.mean(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_10' (type Functional).\n    \n    Input 0 of layer \"conv1d_20\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, None)\n    \n    Call arguments received by layer 'model_10' (type Functional):\n      • inputs=('tf.Tensor(shape=(None, None), dtype=float32)', 'tf.Tensor(shape=(None, None), dtype=float32)')\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m earlystop_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39madam, loss\u001b[38;5;241m=\u001b[39mbinary_crossentropy, metrics\u001b[38;5;241m=\u001b[39m[accuracy, f1, mcc])\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearlystop_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filep3w4r0of.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/sortion/.local/share/miniforge3/envs/intelligent-antibodies/lib/python3.11/site-packages/keras/src/engine/input_spec.py\", line 253, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_10' (type Functional).\n    \n    Input 0 of layer \"conv1d_20\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, None)\n    \n    Call arguments received by layer 'model_10' (type Functional):\n      • inputs=('tf.Tensor(shape=(None, None), dtype=float32)', 'tf.Tensor(shape=(None, None), dtype=float32)')\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[seq_input1, seq_input2],\n",
    "            outputs=[forward(seq_input1, seq_input2)])\n",
    "\n",
    "adam = Adam(learning_rate=1e-4, amsgrad=True, epsilon=1e-6)\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint('run/siamese/model.h5', monitor='val_mcc', mode='max')\n",
    "earlystop_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "model.compile(optimizer=adam, loss=binary_crossentropy, metrics=[accuracy, f1, mcc])\n",
    "\n",
    "\n",
    "model.fit(train_ds_loader, epochs=50, callbacks=[checkpoint_callback, earlystop_callback],\n",
    "          batch_size=64, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-antibodies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
