{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 12:04:33.021138: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-23 12:04:33.206582: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-23 12:04:33.206616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-23 12:04:33.223196: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-23 12:04:33.259076: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = \"torch\"\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from modules.dataset import DatasetFactory\n",
    "from modules.encoding import NLFEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../data/SAbDab\"\n",
    "\n",
    "df_match = pd.read_csv(os.path.join(dataset_dir, \"data.csv\"), sep=\";\")\n",
    "df_seq = pd.read_csv(os.path.join(dataset_dir, \"sequences.csv\"), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>ag</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5kel|ab</td>\n",
       "      <td>5kel|ag</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5kel|ab</td>\n",
       "      <td>6cwt|ag</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5kel|ab</td>\n",
       "      <td>4fp8|ag</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5kel|ab</td>\n",
       "      <td>4yjz|ag</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5kel|ab</td>\n",
       "      <td>6j15|ag</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ab       ag  interaction\n",
       "0  5kel|ab  5kel|ag            1\n",
       "1  5kel|ab  6cwt|ag            0\n",
       "2  5kel|ab  4fp8|ag            0\n",
       "3  5kel|ab  4yjz|ag            0\n",
       "4  5kel|ab  6j15|ag            0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter \n",
    "\n",
    "Remove keys which does not have both an antigen and an anticorps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345323, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df_match[df_match[\"ab\"].isin(df_seq[\"seq_id\"]) & df_match[\"ag\"].isin(df_seq[\"seq_id\"])]\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421821, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "### NLF\n",
    "\n",
    "We want to encode the sequence first, and retrieve the encoded for each sequence in the join later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = NLFEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = df_seq[\"sequence\"].values\n",
    "encoded_seq = encoder.encode(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_id_to_nlf = {seq_id: nlf for seq_id, nlf in zip(df_seq[\"seq_id\"], encoded_seq)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_ag = df_filtered[\"ag\"].map(lambda x: seq_id_to_nlf[x])\n",
    "x_ab = df_filtered[\"ab\"].map(lambda x: seq_id_to_nlf[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimensions = x_ag[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split both datasets\n",
    "X = pd.DataFrame({\"ag\": x_ag, \"ab\": x_ab})\n",
    "y = df_filtered[\"interaction\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ag = np.stack(x_train[\"ag\"].values)\n",
    "x_train_ab = np.stack(x_train[\"ab\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((276258, 1500, 18), (276258, 1500, 18))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ag.shape, x_train_ab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_input1 = layers.Input(shape=input_dimensions, name='seq_ag')\n",
    "seq_input2 = layers.Input(shape=input_dimensions, name='seq_ab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 12:04:56.173341: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Convolutional modules\n",
    "filters = 96\n",
    "\n",
    "conv01 = layers.Conv1D(filters, 11, padding='same', activation=\"relu\")\n",
    "mp1 = layers.MaxPooling1D(3)\n",
    "conv02 = layers.Conv1D(filters*2, 7, padding='same', activation=\"relu\")\n",
    "mp2 = layers.MaxPooling1D(3)\n",
    "conv03 = layers.Conv1D(filters*4, 3, padding='same', activation=\"relu\")\n",
    "mp3 = layers.MaxPooling1D(3)\n",
    "conv04 = layers.Conv1D(filters*2, 3, padding='same', activation=\"relu\")\n",
    "mp4 = layers.MaxPooling1D(3)\n",
    "\n",
    "gru = layers.Bidirectional(layers.GRU(filters, return_sequences=False))\n",
    "\n",
    "def siamese_propagation(x):\n",
    "    x = conv01(x)\n",
    "    x = mp1(x)\n",
    "\n",
    "    x = conv02(x)\n",
    "    x = mp2(x)\n",
    "\n",
    "    x = conv03(x)\n",
    "    x = mp3(x)\n",
    "\n",
    "    x = conv04(x)\n",
    "    x = mp4(x)\n",
    "\n",
    "    x_gru = gru(x)\n",
    "    return x_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(left, right):\n",
    "    left = siamese_propagation(left)\n",
    "    right = siamese_propagation(right)\n",
    "\n",
    "    merge = layers.multiply([left, right])\n",
    "\n",
    "    # merge = layers.Dense(filters*2, activation='relu')(merge)\n",
    "    merge = layers.Dropout(0.2)(merge)\n",
    "    return layers.Dense(1, activation='sigmoid')(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    pred_pos = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = tp / (pred_pos + K.epsilon())\n",
    "    recall = tp / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def mcc(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "    return (tp + tn) / (tp + tn + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_true, y_pred):\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    loss = - K.mean(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[seq_input1, seq_input2],\n",
    "            outputs=[forward(seq_input1, seq_input2)])\n",
    "\n",
    "adam = Adam(learning_rate=1e-4, amsgrad=True, epsilon=1e-6)\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint('run/siamese/model.h5', monitor='val_mcc', mode='max')\n",
    "earlystop_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "model.compile(optimizer=adam, loss=binary_crossentropy, metrics=[accuracy, f1, mcc])\n",
    "\n",
    "model.fit([x_train_ab, x_train_ag], y_train, epochs=50, callbacks=[checkpoint_callback, earlystop_callback],\n",
    "          batch_size=64, verbose=1, validation_split=0.15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-antibodies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
